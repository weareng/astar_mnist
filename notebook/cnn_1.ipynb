{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee00faaf-0f16-497a-a04e-65dc0f8a0fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "481e6970-c9c3-4573-bc66-a8d8705863d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffd3b774-509e-42a1-8cb7-59dbe224341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737b9cc8-1666-4197-b206-255e2c7a6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='../dataset/', train=True, transform=transforms, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='../dataset/', train=False, transform=transforms, download=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c46c25-6399-4346-83a3-a450ff25d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN Model\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.fc1 = nn.Linear(16*7*7, num_classes) # 28 -> 28 -> 14 -> 14 -> 7 (changes due to maxpool)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x) \n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe1ec40-e93b-46b8-8541-33682520d551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Training Loss: 8.1240, Validation Loss: 2.6046\n",
      "Epoch 2/5, Training Loss: 2.6833, Validation Loss: 1.7088\n",
      "Epoch 3/5, Training Loss: 2.0293, Validation Loss: 1.7759\n",
      "Epoch 4/5, Training Loss: 1.6978, Validation Loss: 1.3643\n",
      "Epoch 5/5, Training Loss: 1.4369, Validation Loss: 1.2843\n"
     ]
    }
   ],
   "source": [
    "# Training and validation loop\n",
    "\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "model = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device=device)\n",
    "        y = y.to(device=device)\n",
    "        optimiser.zero_grad() \n",
    "        pred_y = model(X)\n",
    "        loss = criterion(pred_y, y) # mean loss per sample\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        running_loss += loss.item() * X.size(0) \n",
    "        # running_loss = total loss per batch, X.size() refers to (batch_size, channels, height, width)\n",
    "    epoch_loss = running_loss/len(train_loader)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            X = X.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            pred_y = model(X)\n",
    "            loss = criterion(pred_y, y)\n",
    "            running_loss += loss.item() * X.size(0)\n",
    "    epoch_test_loss = running_loss/len(test_loader)\n",
    "    test_losses.append(epoch_test_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}, Validation Loss: {epoch_test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ea1a035-080e-4c3e-b125-44551bb55e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4402,  1.9464, -0.5156]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(1, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb7914e6-36b5-4cfb-b06e-e0d972a27344",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "torch.max(a, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa1c89-0169-49da-b26b-3cfcf794c4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
